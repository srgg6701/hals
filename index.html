<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link href="./dist/output.css" rel="stylesheet" />
    <title>HALS: Sensorimotor AI systems</title>
    <style>
      h1,
      .h1 {
        line-height: 1.75;
      }

      nav {
        margin-bottom: 0.45rem;
      }

      ul {
        list-style: none;
        margin: 1rem auto 0;
        padding: 0;
      }

      li {
        font-size: 1.25rem;
        display: inline-block;
        vertical-align: middle;
      }

      li a {
        color: var(--color-lilac);
        display: block;
        padding: 1rem 0.5rem;
        text-decoration: none;
      }

      li a:hover {
        background-color: var(--color-deep-purple);
        color: #fff;
      }

      .common-problems {
        justify-content: space-evenly;
        padding-bottom: 3rem;
      }

      .common-problems img {
        margin-bottom: 1rem;
        max-height: 85px;
      }
      .common-problems > div {
        font-size: 1.2rem;
        width: 33%;
      }

      .experts {
        align-items: center;
        display: flex;
        vertical-align: middle;
      }

      .experts strong {
        display: block;
        line-height: 1.75;
      }

      .experts img {
        float: left;
        margin: 0.8rem 1rem auto;
        max-width: 110px;
      }

      .text-center.text-blue-grayish span {
        display: inline-block;
      }

      .text-center.text-blue-grayish span::first-letter {
        color: var(--color-deep-purple);
        font-weight: 900;
      }

      .risks div {
        width: 25%;
      }

      .risks img {
        max-height: 92px;
      }

      .arrow-transition {
        color: var(--color-deep-purple);
      }
      .approach-transition img {
        max-width: 100%;
      }

      .how-it-works {
        text-align: left;
      }

      .how-it-works .img-wrapper {
        min-width: 160px;
      }

      .img-wrapper img {
        margin-bottom: 2rem;
        width: 100%;
      }
      .img-wrapper img:hover {
        outline: solid 1px var(--color-deep-purple);
      }
      .marked-list.checkbox {
        padding-right: 40px;
      }
      .marked-list.checkbox li span img {
        margin: auto auto -0.55rem -0.2rem;
      }
      /**/
      #videoModal {
        display: none;
        position: fixed;
        z-index: 1000;
        left: 0;
        top: 0;
        width: 100%;
        height: 100%;
        background-color: rgba(0, 0, 0, 0.7);
      }

      #videoModalContent {
        position: relative;
        width: 80%;
        max-width: 800px;
        margin: 5% auto;
        background: #fff;
        padding: 1rem;
      }

      #videoModal iframe {
        width: 100%;
        height: 450px;
      }

      .close-button {
        background: var(--color-grey);
        border-radius: 50%;
        color: #fff;
        cursor: pointer;
        font-size: 1.5rem;
        height: 2rem;
        position: absolute;
        right: 0;
        top: 0;
        width: 2rem;
      }

      /* smooth scroll top */
      #scrollToTop {
        position: fixed;
        bottom: 2rem;
        right: 2rem;
        background-color: #444;
        color: white;
        border: none;
        border-radius: 50%;
        width: 3rem;
        height: 3rem;
        font-size: 1.5rem;
        cursor: pointer;
        z-index: 999;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.3);
        display: flex;
        align-items: center;
        justify-content: center;
        opacity: 0;
        visibility: hidden;
        transition: opacity 0.4s ease, visibility 0.4s ease;
      }

      #scrollToTop.show {
        opacity: 1;
        visibility: visible;
      }

      #scrollToTop:hover {
        background-color: #666;
      }
    </style>
    <script>
      function showVideoClip() {
        const modal = document.getElementById("videoModal");
        const iframe = document.getElementById("videoFrame");
        iframe.src = "https://www.youtube.com/embed/LaAYuygr7_8";
        modal.style.display = "block";
      }

      function closeVideoModal() {
        const modal = document.getElementById("videoModal");
        const iframe = document.getElementById("videoFrame");
        iframe.src = ""; // Очистка iframe для остановки воспроизведения
        modal.style.display = "none";
      }

      // close the modal when clicking outside of the video content
      window.onclick = function (event) {
        const modal = document.getElementById("videoModal");
        if (event.target == modal) {
          closeVideoModal();
        }
      };
    </script>
  </head>
  <body>
    <main class="w-full">
      <header>
        <nav>
          <ul class="flex justify-between">
            <li class="flex items-center">
              <img
                src="./images/HALS-logo.png"
                alt="HALS Logo"
                class="logo"
                style="margin-right: 1.25rem; max-width: 160px"
              />
            </li>
            <li>
              <a href="#the-problem">1 : The Problem</a>
            </li>
            <li>
              <a href="#the-solution">2 : The Solution</a>
            </li>
            <li>
              <a href="#how-it-works">3 : How it Works</a>
            </li>
            <li>
              <a href="#how-it-appears">4 : How it Appears</a>
            </li>
            <li>
              <a href="#contacts">Contacts</a>
            </li>
          </ul>
        </nav>
        <div
          class="text-center inline-block text-blue-grayish"
          style="font-size: 1.2rem"
        >
          <span>Human-friendly</span>
          <span>Autonomous</span>
          SELF-<span>Learning</span>
          <span>Systems</span>
        </div>
        <span style="color: #888; font-weight: 600"
          ><span style="display: inline-block; padding: 0 1rem">::</span>
          Deep-Tech Startup</span
        >
      </header>
      <hr class="separator" style="margin: 2.2rem auto" />
      <div
        class="flex items-center justify-center text-center"
        style="margin: 0 auto 1rem"
      >
        <img
          style="max-width: 140px; margin-right: 0.8rem"
          src="images/brainware.png"
          alt="BrainWare for Robotics and Autonomous Devices"
        />
        <h1 class="text-left" style="font-weight: 400">
          <div>
            We Design <strong class="text-purple-native">BrainWare</strong>
          </div>
          <div style="padding-left: 1rem">
            for <strong class="text-lilac">Robotics</strong>
            and
          </div>
          <div class="text-deep-turquoise font-bold">Autonomous Devices</div>
        </h1>
      </div>
      <div class="h1 text-3xl">
        <div>It Makes Them Reason</div>
        <div class="text-purple-native">
          — Like <strong>Humans</strong>
          Do.
        </div>
      </div>
      <figure>
        <img
          src="images/sonny.png"
          style="margin: 1.3rem auto; max-width: 430px; width: 100%"
          alt=""
        />
      </figure>
      <hr class="separator" />
      <h1 id="the-problem" class="mb-0">1. The Problem</h1>
      <h3 class="flex gap-4 items-center mt-0 mb-8">
        <img
          style="width: 100%; max-width: 205px"
          src="images/robot-confusion.png"
          alt="Deep Learning Failure"
        />
        <div class="text-left" style="line-height: 1.75">
          The <span style="color: #f00">systematic failure</span> of current AI
          approaches to create provably intelligent systems.
        </div>
      </h3>
      <div
        class="flex gap-4 flex-wrap"
        style="margin: auto; padding: 1.8rem; border: solid 3px #455b687d"
      >
        <div class="experts">
          <img src="images/expert-gary-marcus.jpg" alt="" />
          <p>
            <strong>Gary Marcus:</strong> When billion-dollar AIs break down
            over puzzles a child can do, it’s <b>time to rethink the hype</b>.
          </p>
        </div>
        <div class="experts">
          <img src="images/expert-yan-lecun.png" alt="" />
          <p>
            <strong>Yan LeCun:</strong> [LLMs] … don’t understand the physical
            world, and <b>…cannot reason</b> in any reasonable definition of the
            term.
          </p>
        </div>
        <div class="experts">
          <img src="images/expert-judea-pearl.jpg" alt="" />
          <p>
            <strong>Judea Pearl:</strong> Even today’s most sophisticated
            techniques of statistical ML can’t make the data tell us why. The
            <b>missing ingredient is a "model of reality"…</b>
          </p>
        </div>
      </div>
      <h2 class="mb-10 mt-10">Common Problems</h2>
      <div class="flex common-problems gap-4">
        <div>
          <img src="images/problem-hallucinations.jpg" alt="Hallucinations" />
          <div>Hallucinations</div>
        </div>
        <div>
          <img src="images/problem-data-fragility.png" alt="Data Fragility" />
          <div>Data Fragility</div>
        </div>
        <div>
          <img src="images/problem-datasets.jpg" alt="Huge Datasets" />
          <div>
            Demand of Huge<br />
            Pretrained Models
          </div>
        </div>
      </div>
      <div class="flex common-problems gap-4">
        <div>
          <img src="images/problem-costs.png" alt="Pretraining Costs" />
          <div>Enormous Model<br />Training Cost</div>
        </div>
        <div>
          <img src="images/problem-blackbox.png" alt="Black Box" />
          <div>Black Box Processing</div>
        </div>
        <div>
          <img src="images/problem-no-alignment.png" alt="Alignment Problem" />
          <div>No Consistent Approach<br />to Alignment</div>
        </div>
      </div>
      <h2 class="mt-0 mb-10">
        <span style="color: #f00">Risks</span> and
        <span style="color: darkorange">Long-Term Issues</span>
      </h2>
      <div
        class="flex items-center justify-center text-center gap-4 items-baseline mt-12 risks"
      >
        <div>
          <img src="images/risks-tech-failure.png" alt="Technical Failures" />
          <p>
            <strong>Technical Failures</strong>
            — the risk of AI systems failing in critical situations, leading to
            potential harm or loss.
          </p>
        </div>
        <div>
          <img src="images/risks-investments-loss.png" alt="Investment Loss" />
          <p>
            <strong>Investment Loss</strong>
            — the risk of significant financial losses due to the failure of AI
            systems to deliver expected results or performance.
          </p>
        </div>
        <div>
          <img
            src="images/risks-distracting.png"
            alt="Distracting from alternative approaches"
          />
          <p>
            <strong>Distracting from alternative approaches</strong>
            — the risk of focusing too much on current AI trends, potentially
            overlooking more effective or innovative solutions.
          </p>
        </div>
        <div>
          <img
            src="images/risks-epistemological-corruption.png"
            alt="Epistemological Corruption"
          />
          <p>
            <strong>Epistemological Corruption</strong>
            — the risk of AI systems distorting or misrepresenting knowledge,
            leading to misinformation and misunderstanding.
          </p>
        </div>
      </div>

      <hr class="separator" />

      <h1 id="the-solution">
        <span class="text-purple-native">2. The Solution</span>
        <span class="text-deep-turquoise">Through Paradigm Change</span>
      </h1>
      <h3 class="slim text-lilac" style="margin-bottom: 3rem">
        Transition from
        <span class="text-grey">static pre-training models</span> to
        <span class="text-light-purple">internal self-learning model</span> that
        reflects the spatial-semantic structure of the real world
      </h3>
      <div
        class="flex flex-wrap justify-center items-center text-center gap-4 approach-transition"
      >
        <img src="images/dataset.png" width="406.8" alt="" />
        <img src="images/arrow.png" width="101.13" alt="" />
        <img src="images/self-learning.png" width="420.86" alt="" />
      </div>
      <h3 class="slim" style="margin-top: 3rem">This approach ensures:</h3>
      <ul class="marked-list checkbox">
        <li>
          Elimination of the need for resource-hungry external datasets
          <span class="arrow-transition"
            >No Enormous External Costs
            <img src="images/checkbox.svg" width="32px" alt=""
          /></span>
        </li>
        <li>
          Dynamic adaptation to changes in the environment
          <span class="arrow-transition"
            >No Data Fragility
            <img src="images/checkbox.svg" width="32px" alt=""
          /></span>
        </li>
        <li>
          Semantic analysis of events and objects based on causality
          <span class="arrow-transition"
            >No Hallucinations
            <img src="images/checkbox.svg" width="32px" alt=""
          /></span>
        </li>
        <li>
          Continuous accumulation of knowledge about the world
          <span class="arrow-transition"
            >No Epistemological Corruption
            <img src="images/checkbox.svg" width="32px" alt=""
          /></span>
        </li>
        <li>
          Transparency of the intentions and actions of AI ​​agent
          <span class="arrow-transition"
            >No Black Box Processing Issue
            <img src="images/checkbox.svg" width="32px" alt=""
          /></span>
        </li>
        <li>
          ​​Conditions for implementing alignment
          <span class="arrow-transition"
            >No Contradiction to Human Values
            <img src="images/checkbox.svg" width="32px" alt=""
          /></span>
        </li>
      </ul>

      <hr class="separator" />

      <h1 id="how-it-works" class="text-purple-native">3. How it Works</h1>
      <img
        style="width: 100%; max-width: 700px"
        src="images/system-engineering-neuroscience.png"
        alt="System Engineering Powered by Neuroscience"
      />

      <hr class="separator" />

      <h3 class="slim">How it Will Look in a Demo</h3>

      <hr class="separator" />

      <h4>1. Generating an Inner Model of the Environment</h4>
      <div
        class="flex flex-col sm:flex-row sm:items-start sm:justify-center"
        style="gap: 38px"
      >
        <div style="max-width: 172px">
          <img
            style="max-width: 100%"
            src="images/model-actual-reality.png"
            alt=""
          />
        </div>
        <div style="max-width: 398px">
          <img style="max-width: 100%" src="images/model-stages.png" alt="" />
        </div>
      </div>
      <h4 class="mt-10">2. Detecting a Reactive Object</h4>
      <img
        style="max-width: 700px; width: 100%"
        src="images/detecting-reactive-object.png"
        alt=""
      />
      <h3 style="margin: 3rem auto 1rem">Stages of Demo</h3>
      <h4>Generating an Inner Model</h4>
      <ol class="marked-list">
        <li>An agent appears on the scene.</li>
        <li>
          The state of its memory can be observed, which should display a model
          of its environment. At first, the memory is empty ("tabula rasa").
        </li>
        <li>
          As the environment is investigated, objects present in this
          environment begin to appear in the agent’s memory.
        </li>
      </ol>
      <h4>Detecting a Reactive Object</h4>
      <ol class="marked-list">
        <li>The agent approaches an unknown object.</li>
        <li>
          When the distance between them decreases to a certain point, the
          latter reacts to this approach (runs away)
        </li>
        <li>
          Agent recognizes this behavior as attributed to "reactive" object.
          That means that such an object may be alive.
        </li>
        <li>
          Agent assigns special attributes to such an object, including
          corresponding policies for safe interaction with it in the future.
        </li>
      </ol>

      <hr class="separator" />

      <h3 class="slim">What is Going on Behind the Scenes</h3>

      <hr class="separator" />
      <div
        class="flex flex-wrap justify-between items-center text-center how-it-works"
        style="margin: 2rem auto"
      >
        <div class="img-wrapper" style="width: 15.9%">
          <img
            class="cursor-pointer"
            onclick="location.href='images/how-it-works-1.png'"
            src="images/how-it-works-1.png"
            alt=""
          />
          Generates Real World Object Models from Sensory Data.
        </div>
        <div class="img-wrapper" style="width: 26.3%">
          <img
            class="cursor-pointer"
            onclick="location.href='images/how-it-works-2.png'"
            src="images/how-it-works-2.png"
            alt=""
          />
          Stores Knowledge in Distributed Communicating Cognitive Modules,
          Enabling Invariant Object Representations.
        </div>
        <div class="img-wrapper" style="width: 26.5%">
          <img
            class="cursor-pointer"
            onclick="location.href='images/how-it-works-3.png'"
            src="images/how-it-works-3.png"
            alt=""
          />
          Interacts with Objects Based on Existing Knowledge of Their Physical
          and Behavioral Properties.
        </div>
        <div class="img-wrapper" style="width: 26.3%">
          <img
            class="cursor-pointer"
            onclick="location.href='images/how-it-works-4.png'"
            src="images/how-it-works-4.png"
            alt=""
          />
          Accumulates Knowledge About Objects Through Interaction with the
          World, persistently increasing efficiency.
        </div>
      </div>

      <hr class="separator" />

      <h2>Theoretical Basis and Implementation Means</h2>

      <div class="mt-10 mb-0">
        <div
          class="flex flex-col sm:flex-row sm:items-start sm:justify-between gap-4"
        >
          <!-- Thousand Brains -->
          <div class="flex items-start gap-3 max-w-md">
            <img
              src="images/tbp-logo.jpg"
              alt="Thousand Brains"
              class="w-10 h-10 shrink-0"
            />
            <div class="text-sm leading-snug">
              <p>
                <strong class="text-black">Thousand Brains Theory</strong>
                <span class="text-black">(Jeff Hawkins)</span>
              </p>
              <p class="whitespace-nowrap">
                <span
                  class="cursor-pointer"
                  onclick="location.href='https://thousandbrainsproject.readme.io/docs'"
                  >Platform for Designing Sensorimotor AI</span
                >
                <a href="https://numenta.com">(Numenta)</a>
              </p>
            </div>
          </div>
          <!-- FAI2LCA -->
          <div class="flex items-start gap-3 max-w-md">
            <img
              src="images/fai2lca-logo.png"
              alt="FAI2LCA"
              class="w-10 h-10 shrink-0"
            />
            <div class="text-sm leading-snug">
              <p>
                <strong class="text-black">FAI2LCA</strong>
                <span class="text-black">(Sergei Klevtsov)</span>
              </p>
              <p class="text-purple-native">
                Friendly AI Two-Level Cognitive Architecture
              </p>
            </div>
          </div>
        </div>
      </div>
      <div id="videoModal">
        <div id="videoModalContent">
          <span class="close-button" onclick="closeVideoModal()">&times;</span>
          <iframe
            id="videoFrame"
            src=""
            frameborder="0"
            allowfullscreen
          ></iframe>
        </div>
      </div>
      <ul class="marked-list" style="margin-top: 1.5rem">
        <li>
          <span
            style="
              background-color: #eeeeff;
              display: inline-block;
              cursor: pointer;
            "
            onclick="showVideoClip()"
            >More about Thousand Brains Theory</span
          >
          (the video of 3:50 will appear in a pop-up)
        </li>
      </ul>
      <hr class="separator" />

      <h1 id="how-it-appears">4. How it Appears in the Physical Environment</h1>

      <h3 class="slim">
        HALS vs Conventional Robot: Key Differences in Applied Strategies
      </h3>
      <p>
        The best way to understand what a device (such as a robot) can or cannot
        do is to compare its performance with that of another device developed
        on different principles. Below is a test run of a typical task for an
        autonomous robot: locating a target object in an industrial warehouse,
        specifically, a box marked with a red label. The location of this object
        is not known in advance; it may be obstructed by other items, or the red
        mark may be on a side not visible from a typical angle. Performance on
        such tasks can be considered a reliable indicator of the intelligence of
        an autonomous device—or, more broadly, of the presence of cognition.
      </p>
      <p>
        We describe strategies for performing this task using a robot controlled
        by an AI operating on pre-trained models (a Conditional Robot, or CR),
        and HALS, which builds an internal model of its environment in real
        time.
      </p>

      <p class="font-bold">Several key factors:</p>

      <h3>1. Approaches to Location Map Construction and Use CR using SLAM:</h3>

      <p>
        If a CR employs SLAM (Simultaneous Localization and Mapping) to
        construct maps, those maps are usually geometric. It can navigate all
        premises and register constraints. However, to "view all objects from
        all angles" for the semantic identification of a mark, it must
        constantly run its object detection module on camera data.
      </p>

      <p class="font-bold">Effectiveness of Detection:</p>

      <p>The CR’s perception module (trained on datasets) may be:</p>
      <ul class="marked-list">
        <li>
          <p>
            <strong>Not robust to angles of view:</strong>
            The effectiveness of detecting objects (especially small details
            like tags) highly depends on the angle, lighting, and partial
            occlusion. Even if it "looks" from all sides, the detector may fail
            to identify a mark if it is seen from an unusual angle or partially
            blocked.
          </p>
        </li>
        <li>
          <p>
            <strong>Computationally expensive:</strong>
            Continuously analyzing the video stream with all possible angles and
            searching for a specific mark imposes enormous computational load.
          </p>
        </li>
        <li>
          <p>
            <strong>Lack of structural object understanding:</strong>
            A CR does not build a 3D model of the object "on the fly" as HALS
            does through reference frames. It merely attempts to "find" a known
            template (mark) in 2D images or 3D data. If the mark is on a box
            edge that is currently hidden or partially blocked, the CR won’t
            "decide" to go around the object to see other edges unless
            explicitly instructed by a specific search strategy.
          </p>
        </li>
      </ul>

      <h3>2. Exploration and Search Strategy</h3>
      <div
        class="flex flex-col sm:flex-row sm:items-start sm:justify-between gap-4"
      >
        <p class="flex items-start gap-3 max-w-md">
          <strong>CR:</strong> Its exploration strategy is likely either
          pre-programmed (e.g., perimeter sweep followed by a specific route) or
          based on space coverage (to build a complete geometric map).
          Purposeful search for visual marks on all surfaces of all objects is a
          highly complex task when it comes to programming effective CR
          strategies. The CR may simply "scan" visible surfaces, and if the mark
          is not in a good angle, it will miss it. To ensure that the CR
          accesses all surfaces of all objects, an exceptionally complex
          movement and inspection strategy would be required.
        </p>
        <p class="flex items-start gap-3 max-w-md">
          <strong class="text-purple-native">HALS:</strong> Its drive to build a
          coherent model principle means that it doesn’t merely cover space but
          attempts to understand the structure of each object and the spatial
          arrangement of all detected entities. When it builds an object model
          through reference frames, it gradually gathers information about its
          various sides and surfaces during the exploration process. Detecting a
          marked object becomes a part of building the full model.
        </p>
      </div>

      <h3>3. Processing Incomplete Information and Uncertainty</h3>
      <div
        class="flex flex-col sm:flex-row sm:items-start sm:justify-between gap-4"
      >
        <p class="flex items-start gap-3 max-w-md">
          <strong>CR:</strong> If an object is partially obscured by items that
          are poorly recognized by CR detectors, these items may be treated as
          "noise" or merged with the background. The CR may fail to separate the
          object from these interfering elements to analyze it in detail.
        </p>
        <p class="flex items-start gap-3 max-w-md">
          <strong class="text-purple-native">HALS:</strong> By building the
          model on-the-fly, HALS tries to analyze all observable entities in its
          perception. It models all objects within sensor range, enabling
          semantic interpretation and representing the object even when it is
          partially occluded by others.
        </p>
      </div>

      <h3>4. Lack of Intentionality</h3>
      <div
        class="flex flex-col sm:flex-row sm:items-start sm:justify-between gap-4"
      >
        <p class="flex items-start gap-3 max-w-md">
          <strong>CR:</strong> Performs tasks based on predefined algorithms. It
          lacks an internal "drive to understand"—that is, a cognitive mechanism
          operating with general representations of semantic object boundaries.
        </p>
        <p class="flex items-start gap-3 max-w-md">
          <strong class="text-purple-native">HALS:</strong> Constructs a
          coherent model of reality as its higher-order goal. In this sense, the
          agent can be described as intentional. The process of understanding is
          continuous, iteratively refining its perception of the surrounding
          environment and the causes within it.
        </p>
      </div>

      <h3>
        5. Why a CR Theoretically Can Solve This Problem but Practically the
        Solution Is Too Expensive and Unreliable
      </h3>
      <p>
        Theoretically, it is possible to program a CR to pursue its goal so
        persistently that the behavior borders on "maniacal," eventually leading
        to a formal solution. For example, by using:
      </p>
      <ul class="marked-list">
        <li>
          <p>
            <strong>Super-detailed scanning:</strong>
            Instruct the CR to methodically scan every inch of the warehouse,
            rotating cameras and sensors in all directions.
          </p>
        </li>
        <li>
          <p>
            <strong>Multiple detectors:</strong>
            Apply a variety of detectors trained on tags in different
            conditions.
          </p>
        </li>
        <li>
          <p>
            <strong>Heuristics and brute-force:</strong>
            If something appears on a non-activated object but the mark is not
            visible, program the CR to perform additional maneuvers around that
            object.
          </p>
        </li>
        <li>
          <p>
            <strong>Repeated passes:</strong>
            If no detection is made during the first attempt, restart with
            different parameters.
          </p>
        </li>
      </ul>
      <p>However, such an approach is questionable due to:</p>
      <h3>6. Enormous Resource and Time Costs for the Agent</h3>
      <ul class="marked-list">
        <li>
          <p>
            <strong>Computational resources:</strong>
            Such a "maniacal" search involving video stream analysis, detector
            usage, and redundant trajectory planning would be extremely
            resource-heavy.
          </p>
        </li>
        <li>
          <p>
            <strong>Execution time:</strong>
            Searching "at any cost" may take excessive time, making it
            impractical where speed matters.
          </p>
        </li>
        <li>
          <p>
            <strong>Energy consumption (in mobile robots):</strong>
            Prolonged redundant operations lead to high energy usage.
          </p>
        </li>
      </ul>
      <h3>
        7. Fragility, Rigidity, and Complexity of Development and Maintenance
      </h3>
      <p>
        Designing and debugging such a "maniacal" search strategy for CR is an
        extremely difficult engineering challenge. Maintaining and updating this
        system would be a nightmare, since such a strategy must be
        custom-developed for a specific task configuration. Minor changes in the
        environment (e.g., lighting, presence of atypical objects, target shape
        variations, or just a change in the mark color) may require a complete
        reprogramming or recalibration of the entire strategy.
      </p>
      <h3>8. Harmful Side Effects of "Maniacal" Behavior</h3>
      <p>
        In the real world, such a robot "obsessed" with finding a mark "at any
        cost" may cause problems: block pathways, inefficiently use space, or
        act unpredictably toward other agents (humans or robots).
      </p>
      <h3>9. Conclusion</h3>
      <p>
        Despite being aware of the target object, CR faces fundamental
        limitations in locating it, rooted in the rigidity of its search
        strategy. Its ability to "see" the red mark depends on the quality of
        pre-trained detectors and its software’s computational capabilities, but
        not on any actual understanding of the surrounding world. Solving a task
        that is trivial for an agent capable of cognition requires enormous
        resources from a CR — and even with such resources, a reliable outcome
        remains uncertain. HALS addresses this problem in a fundamentally
        different way. Its sensorimotor approach is aimed at actively
        constructing a coherent 3D model of its environment, in which each
        object possesses its own semantics, including its relations to other
        objects. HALS’s search strategy is grounded in an understanding of the
        environment’s topology: it recognizes the spatial arrangement of
        objects, formulates hypotheses about their properties, and tests them.
        This approach grants HALS a categorical advantage over current
        mainstream methods in solving a wide range of tasks — both within
        robotics and beyond.
      </p>

      <hr class="separator" />

      <h1 id="contacts" class="text-lilac" style="margin: 0 auto 2.5rem">
        Contacts
      </h1>

      <div class="flex flex-col sm:flex-row sm:items-start sm:justify-center">
        <p style="max-width: 260px; margin: 0">
          For more information on HALS or the <strong>pitch deck</strong>, please contact us at:
          <a
            href="mailto:&#115;&#114;&#103;&#103;&#54;&#55;&#48;&#49;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;"
          >
            &#115;&#114;&#103;&#103;&#54;&#55;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;
          </a>
        </p>
        <div style="max-width: 330px; vertical-align: top">
          <img style="max-height: 146px" src="images/founder-srgg.png" alt="" />
          <div>
            <strong
              style="display: inline-block; text-align: center; width: 100%"
              >Sergei Klevtsov</strong
            >
            <p style="padding-left: 3.4rem">
              Founder, Project Lead.
              <br />
              AI Researcher, System Architect. Over 15 years of Research and IT
              expertise.
            </p>
          </div>
        </div>
        <div style="max-width: 330px; vertical-align: top">
          <img
            style="max-height: 146px"
            src="images/founder-sergii.png"
            alt=""
          />
          <div>
            <strong
              style="display: inline-block; text-align: center; width: 100%"
              >Sergii Korobko</strong
            >
            <p style="padding-left: 3.7rem">
              Co-founder, Technical Principal.
              <br />
              Software Architect. Over 20 years of IT expertise.
            </p>
          </div>
        </div>
      </div>
      <button id="scrollToTop" title="Back to top">↑</button>
    </main>
    <script>
      const scrollBtn = document.getElementById("scrollToTop");
      console.log("scrollBtn", scrollBtn);
      scrollBtn.addEventListener("click", function () {
        window.scrollTo({
          top: 0,
          behavior: "smooth",
        });
      });

      window.addEventListener("scroll", function () {
        if (window.scrollY > 300) {
          console.log("showing scroll button");
          scrollBtn.classList.add("show");
        } else {
          scrollBtn.classList.remove("show");
        }
      });
    </script>
  </body>
</html>
